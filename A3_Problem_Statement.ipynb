{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "A3_Problem_Statement.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/en-ashay/ML-codes/blob/master/A3_Problem_Statement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fy1ry2Otk7C"
      },
      "source": [
        "Download the dataset from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=0B4c_CWtMboiGRHJhWWZMbGpQazFxcHNfUkhnQ1pQU09IeXFR\n",
        "\n",
        "If you read the dataset by importing pandas library and using pd.read_csv():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XmpYI9Ltk7D"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as st"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGBx789VQ4tJ"
      },
      "source": [
        "# Checking for possible functions in scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of5xrHf9Plxe",
        "outputId": "df7d9444-2886-4a13-a906-fb4d3ee75fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "dir(st.norm)\n",
        "\n",
        "# dir(st.norm.pdf) to check details of norm.pdf\n",
        "#dir(std.norm.logpdf)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_argcheck',\n",
              " '_argcheck_rvs',\n",
              " '_cdf',\n",
              " '_cdf_single',\n",
              " '_cdfvec',\n",
              " '_construct_argparser',\n",
              " '_construct_default_doc',\n",
              " '_construct_doc',\n",
              " '_ctor_param',\n",
              " '_entropy',\n",
              " '_fit_loc_scale_support',\n",
              " '_fitstart',\n",
              " '_get_support',\n",
              " '_isf',\n",
              " '_logcdf',\n",
              " '_logpdf',\n",
              " '_logsf',\n",
              " '_mom0_sc',\n",
              " '_mom1_sc',\n",
              " '_mom_integ0',\n",
              " '_mom_integ1',\n",
              " '_munp',\n",
              " '_nnlf',\n",
              " '_nnlf_and_penalty',\n",
              " '_open_support_mask',\n",
              " '_parse_args',\n",
              " '_parse_args_rvs',\n",
              " '_parse_args_stats',\n",
              " '_pdf',\n",
              " '_penalized_nnlf',\n",
              " '_ppf',\n",
              " '_ppf_single',\n",
              " '_ppf_to_solve',\n",
              " '_ppfvec',\n",
              " '_random_state',\n",
              " '_reduce_func',\n",
              " '_rvs',\n",
              " '_sf',\n",
              " '_stats',\n",
              " '_stats_has_moments',\n",
              " '_support_mask',\n",
              " '_unpack_loc_scale',\n",
              " '_updated_ctor_param',\n",
              " 'a',\n",
              " 'b',\n",
              " 'badvalue',\n",
              " 'cdf',\n",
              " 'entropy',\n",
              " 'expect',\n",
              " 'extradoc',\n",
              " 'fit',\n",
              " 'fit_loc_scale',\n",
              " 'freeze',\n",
              " 'generic_moment',\n",
              " 'interval',\n",
              " 'isf',\n",
              " 'logcdf',\n",
              " 'logpdf',\n",
              " 'logsf',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'moment',\n",
              " 'moment_type',\n",
              " 'name',\n",
              " 'nnlf',\n",
              " 'numargs',\n",
              " 'pdf',\n",
              " 'ppf',\n",
              " 'random_state',\n",
              " 'rvs',\n",
              " 'sf',\n",
              " 'shapes',\n",
              " 'stats',\n",
              " 'std',\n",
              " 'support',\n",
              " 'var',\n",
              " 'vecentropy',\n",
              " 'xtol']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2SRCFRLtk7G"
      },
      "source": [
        "data = pd.read_csv(\"data.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZZc8gbatk7I",
        "outputId": "4327ce38-f233-42cf-a97b-98119f8acca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         M        17.99  ...          0.4601                  0.11890\n",
              "1         M        20.57  ...          0.2750                  0.08902\n",
              "2         M        19.69  ...          0.3613                  0.08758\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGR3RKgptk7L"
      },
      "source": [
        "Remove the first column 'id' and the last column 'Unnamed:32' from this dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COIhLGnkI31Q",
        "outputId": "67f69a19-048f-410a-d36f-ecd098999339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Listing all the columns\n",
        "print(data.columns.tolist())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw6lqCt4tk7L"
      },
      "source": [
        "data.drop(labels=[data.columns[0],data.columns[32]],axis=1,inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62BakY6itk7N",
        "outputId": "a67b23b5-d136-4fb0-e480-2ee0bfc6095f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         M        17.99  ...          0.4601                  0.11890\n",
              "1         M        20.57  ...          0.2750                  0.08902\n",
              "2         M        19.69  ...          0.3613                  0.08758\n",
              "3         M        11.42  ...          0.6638                  0.17300\n",
              "4         M        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJsxGIM7tk7P"
      },
      "source": [
        "The task is to determine the best fitting probability distribution on each column data (Sample Data of the Random Variable) of the dataset, out of the possible choices of probability distributions: Normal(Symmetric), Rayleigh(Skewed) or Binomial. \n",
        "\n",
        "So, let's see that how are we going to do that for a single column data and then we have to repeat this process for rest of the columns: \n",
        "\n",
        "Step 1: First, we will check whether the Random Variable is Discrete or Continous by checking that how many unique values are there in the single column of the Random Variable and does the Random Variable has string or floating point or integer values? Usually, Discrete Random Variables have either Integer or String values whereas continous random variables have floating point values and also because the values are not sparse (0s or 1s) in continous random variables and they are dense (floating point values) so values don't repeat much and hence the number of unique values are almost equal to the total number of values in the column. As an example, lets take one by one two columns: 'diagnosis' and 'radius_mean': "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSf7vV-ptk7Q"
      },
      "source": [
        "diagnosis_unique_values = data['diagnosis'].unique()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTqjjIhVJXrc",
        "outputId": "7ce4314f-0907-4ad7-fc7e-2fb7c1426a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data['diagnosis'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LFdcDcztk7R"
      },
      "source": [
        "radius_mean_unique_values = data['radius_mean'].unique()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPJcjujWJeJ6",
        "outputId": "e0f34136-941a-487a-a4e5-94777aff1faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data['radius_mean'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.34    4\n",
              "12.77    3\n",
              "15.46    3\n",
              "12.89    3\n",
              "13.05    3\n",
              "        ..\n",
              "12.31    1\n",
              "18.81    1\n",
              "13.30    1\n",
              "23.09    1\n",
              "18.25    1\n",
              "Name: radius_mean, Length: 456, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvllL9mmtk7U",
        "outputId": "a6437ed7-2162-46a4-926a-51fbeb6148b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "diagnosis_unique_values"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['M', 'B'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjSxZdkttk7W",
        "outputId": "d123edb7-26b3-48c1-8b8f-274459fa7d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "radius_mean_unique_values"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17.99 , 20.57 , 19.69 , 11.42 , 20.29 , 12.45 , 18.25 , 13.71 ,\n",
              "       13.   , 12.46 , 16.02 , 15.78 , 19.17 , 15.85 , 13.73 , 14.54 ,\n",
              "       14.68 , 16.13 , 19.81 , 13.54 , 13.08 ,  9.504, 15.34 , 21.16 ,\n",
              "       16.65 , 17.14 , 14.58 , 18.61 , 15.3  , 17.57 , 18.63 , 11.84 ,\n",
              "       17.02 , 19.27 , 16.74 , 14.25 , 13.03 , 14.99 , 13.48 , 13.44 ,\n",
              "       10.95 , 19.07 , 13.28 , 13.17 , 18.65 ,  8.196, 12.05 , 13.49 ,\n",
              "       11.76 , 13.64 , 11.94 , 18.22 , 15.1  , 11.52 , 19.21 , 14.71 ,\n",
              "       13.05 ,  8.618, 10.17 ,  8.598,  9.173, 12.68 , 14.78 ,  9.465,\n",
              "       11.31 ,  9.029, 12.78 , 18.94 ,  8.888, 17.2  , 13.8  , 12.31 ,\n",
              "       16.07 , 13.53 , 18.05 , 20.18 , 12.86 , 11.45 , 13.34 , 25.22 ,\n",
              "       19.1  , 12.   , 18.46 , 14.48 , 19.02 , 12.36 , 14.64 , 14.62 ,\n",
              "       15.37 , 13.27 , 13.45 , 15.06 , 20.26 , 12.18 ,  9.787, 11.6  ,\n",
              "       14.42 , 13.61 ,  6.981,  9.876, 10.49 , 13.11 , 11.64 , 22.27 ,\n",
              "       11.34 ,  9.777, 12.63 , 14.26 , 10.51 ,  8.726, 11.93 ,  8.95 ,\n",
              "       14.87 , 17.95 , 11.41 , 18.66 , 24.25 , 14.5  , 13.37 , 13.85 ,\n",
              "       19.   , 19.79 , 12.19 , 15.46 , 16.16 , 15.71 , 18.45 , 12.77 ,\n",
              "       11.71 , 11.43 , 14.95 , 11.28 ,  9.738, 16.11 , 12.9  , 10.75 ,\n",
              "       11.9  , 11.8  , 14.44 , 13.74 ,  8.219,  9.731, 11.15 , 13.15 ,\n",
              "       12.25 , 17.68 , 16.84 , 12.06 , 10.9  , 11.75 , 19.19 , 19.59 ,\n",
              "       12.34 , 23.27 , 14.97 , 10.8  , 16.78 , 17.47 , 12.32 , 13.43 ,\n",
              "       11.08 , 10.66 ,  8.671,  9.904, 16.46 , 13.01 , 12.81 , 27.22 ,\n",
              "       21.09 , 15.7  , 15.28 , 10.08 , 18.31 , 11.81 , 12.3  , 14.22 ,\n",
              "        9.72 , 14.86 , 12.91 , 13.77 , 18.08 , 19.18 , 14.45 , 12.23 ,\n",
              "       17.54 , 23.29 , 13.81 , 12.47 , 15.12 , 17.01 , 15.27 , 20.58 ,\n",
              "       28.11 , 17.42 , 14.19 , 13.86 , 11.89 , 10.2  , 19.8  , 19.53 ,\n",
              "       13.65 , 13.56 , 10.18 , 15.75 , 14.34 , 10.44 , 15.   , 12.62 ,\n",
              "       12.83 , 17.05 , 11.32 , 11.22 , 20.51 ,  9.567, 14.03 , 23.21 ,\n",
              "       20.48 , 17.46 , 12.42 , 11.3  , 13.75 , 19.4  , 10.48 , 13.2  ,\n",
              "       12.89 , 10.65 , 20.94 , 11.5  , 19.73 , 17.3  , 19.45 , 13.96 ,\n",
              "       19.55 , 15.32 , 15.66 , 15.53 , 20.31 , 17.35 , 17.29 , 15.61 ,\n",
              "       17.19 , 20.73 , 10.6  , 13.59 , 12.87 , 10.71 , 14.29 , 11.29 ,\n",
              "       21.75 ,  9.742, 17.93 , 11.33 , 18.81 , 19.16 , 11.74 , 16.24 ,\n",
              "       12.58 , 11.26 , 11.37 , 14.41 , 14.96 , 12.95 , 11.85 , 12.72 ,\n",
              "       10.91 , 20.09 , 11.46 ,  9.   , 13.5  , 11.7  , 14.61 , 12.76 ,\n",
              "       11.54 ,  8.597, 12.49 ,  9.042, 12.43 , 10.25 , 20.16 , 20.34 ,\n",
              "       12.2  , 12.67 , 14.11 , 12.03 , 16.27 , 16.26 , 16.03 , 12.98 ,\n",
              "       11.25 , 17.06 , 12.99 , 18.77 , 10.05 , 23.51 ,  9.606, 11.06 ,\n",
              "       19.68 , 10.26 , 14.76 , 11.47 , 11.95 , 11.66 , 25.73 , 15.08 ,\n",
              "       11.14 , 12.56 , 13.87 ,  8.878,  9.436, 12.54 , 13.3  , 16.5  ,\n",
              "       13.4  , 20.44 , 20.2  , 12.21 , 21.71 , 22.01 , 16.35 , 15.19 ,\n",
              "       21.37 , 20.64 , 13.69 , 16.17 , 10.57 , 13.46 , 13.66 , 11.27 ,\n",
              "       11.04 , 12.39 , 14.6  , 13.88 ,  8.734, 15.49 , 21.61 , 12.1  ,\n",
              "       14.06 , 13.51 , 12.8  , 17.91 , 12.96 , 12.94 , 10.94 , 16.14 ,\n",
              "       12.85 , 12.27 , 11.36 ,  9.397, 15.13 ,  9.405, 15.5  , 12.7  ,\n",
              "       11.16 , 11.57 , 14.69 , 11.61 , 10.03 , 11.13 , 14.9  , 12.4  ,\n",
              "       18.82 , 13.98 , 14.04 , 14.02 , 10.97 , 17.27 , 13.78 , 18.03 ,\n",
              "       11.99 , 17.75 , 14.8  , 14.53 , 21.1  , 11.87 , 13.38 , 11.63 ,\n",
              "       13.21 ,  9.755, 17.08 , 27.42 , 14.4  , 13.24 , 13.14 ,  9.668,\n",
              "       17.6  , 11.62 ,  9.667, 12.04 , 14.92 , 10.88 , 14.2  , 13.9  ,\n",
              "       11.49 , 16.25 , 12.16 , 13.47 , 13.7  , 15.73 , 19.44 , 11.68 ,\n",
              "       16.69 , 17.85 , 18.01 , 13.16 , 12.65 , 18.49 , 20.59 , 15.04 ,\n",
              "       13.82 , 23.09 ,  9.268,  9.676, 12.22 , 16.3  , 14.81 , 15.05 ,\n",
              "       19.89 , 12.88 , 12.75 ,  9.295, 24.63 ,  9.847,  8.571, 13.94 ,\n",
              "       12.07 , 11.67 , 13.68 , 20.47 , 10.96 , 20.55 , 14.27 , 11.69 ,\n",
              "        7.729,  7.691, 14.47 , 14.74 , 13.62 , 10.32 ,  9.683, 10.82 ,\n",
              "       10.86 ,  9.333, 10.29 , 10.16 ,  9.423, 14.59 , 11.51 , 14.05 ,\n",
              "       11.2  , 15.22 , 20.92 , 21.56 , 20.13 , 16.6  , 20.6  ,  7.76 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvz9LYENtk7Y"
      },
      "source": [
        "Let's see that in each of the cases, how many unique values are there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAaaXe5qtk7Y",
        "outputId": "96d9fad0-409b-4609-8ba2-3a6108232ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(diagnosis_unique_values)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaLCeOdctk7a",
        "outputId": "cbdb79b0-4b9f-4cbb-c969-8d25a23c137e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(radius_mean_unique_values)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIpR02Cjtk7c"
      },
      "source": [
        "As you can see that in our discrete random variable of 'diagnosis', we have very limited values, only two in number and they are string in nature : ['B, 'M']\n",
        "\n",
        "Whereas, in our continous random variable of 'radius_mean', we can see the numbe rof unique values is huge and it's 456 which is not much smaller than 569, the number of rows in a column. Moreover, the nature or datatype of values is floating point. \n",
        "\n",
        "So, lets write this concept in the form of the code: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiYzM3Oqdqks",
        "outputId": "5f4a7b45-625c-403d-f4af-efc9ba5cbc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                   object\n",
              "radius_mean                float64\n",
              "texture_mean               float64\n",
              "perimeter_mean             float64\n",
              "area_mean                  float64\n",
              "smoothness_mean            float64\n",
              "compactness_mean           float64\n",
              "concavity_mean             float64\n",
              "concave points_mean        float64\n",
              "symmetry_mean              float64\n",
              "fractal_dimension_mean     float64\n",
              "radius_se                  float64\n",
              "texture_se                 float64\n",
              "perimeter_se               float64\n",
              "area_se                    float64\n",
              "smoothness_se              float64\n",
              "compactness_se             float64\n",
              "concavity_se               float64\n",
              "concave points_se          float64\n",
              "symmetry_se                float64\n",
              "fractal_dimension_se       float64\n",
              "radius_worst               float64\n",
              "texture_worst              float64\n",
              "perimeter_worst            float64\n",
              "area_worst                 float64\n",
              "smoothness_worst           float64\n",
              "compactness_worst          float64\n",
              "concavity_worst            float64\n",
              "concave points_worst       float64\n",
              "symmetry_worst             float64\n",
              "fractal_dimension_worst    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNon942yebTz",
        "outputId": "4872d967-80c8-41f0-accb-7f8c4b7bc08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(type(data['diagnosis'][0]))\n",
        "print(type(data['diagnosis']))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dX_uRCqtk7d"
      },
      "source": [
        "def determine_random_variable_type(column_name):\n",
        "    \n",
        "    if (type(data[column_name][0]) == str or type(data[column_name][0]) == int) and ((data[column_name].nunique()) < len(data[column_name])):\n",
        "        \n",
        "        return 'discrete'\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        return 'continous'"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odb3MXbCtk7e"
      },
      "source": [
        "The above function will take the name of the single column of the dataset and access the data of that column from the dataset and check the datatype or nature of the values inside that column and also the total number of unique values in that column and check the conditions for the random variable or that specific column being discrete or continous and returns the the type of random variable as strings 'discrete' or 'continous'. \n",
        "\n",
        "Now, the next task is to calculate the value of the best estimator of the population parameter of the probability distribution from which a specific column data is being sampled. In case of discrete random variables, it's pretty easy to determine that: If there are only two unique values in the column data, then it's binomial distribution and multinomial if there are more than two unique values. \n",
        "\n",
        "But, the real challenge lies in case of continous random variables, where it is difficult to determine that from which continous probability distibution the column data is being sampled. We have two options here: Either Normal (Symmetric) or Rayleigh (Skewed). So, in this case we have to find the best fit of our data on both the distributions and then select the distribution with the BESTEST FIT. \n",
        "\n",
        "Well, now the question arrises that how we are going to do that. We know that the Log Likelihood Function Value calculated on the data determines the quality of fit of data on the presumed distribution and if we maximize that value then we get the best fit of a specific probability distribution on the data. so, we first find the best fit of normal distibution on our continous data and then we find the best fit of Rayleigh Distribution on our continous data by maximizing the Log Likelihood Function Value for both the cases and because we have to select that distribution which gives us the bestest fit so we will end up selecting the distribution whose Log Likelihood Function value is maximum among both maxmized Log Likelihood Function Values. \n",
        "\n",
        "The problem is that in order to find the Log Likelihood Function value evaluated in case of fit of specific distribution on the data, we need the PDF of that distribution, which we know but we dont know the values of best estimators of population parameters:\n",
        "\\begin{equation}\n",
        "\\mu, \\sigma\n",
        "\\end{equation}\n",
        "of Normal Distribution and best estimator of population parameter, \n",
        "\\begin{equation}\n",
        "\\sigma (mode)\n",
        "\\end{equation}\n",
        "\n",
        "of Rayleigh Distribution. \n",
        "\n",
        "Now, how do we get the values of the best estimators of population parameters of respective distributions. Well, we know the answer to this question and that is by Maximum Log Likelihood Estimation. We know that the data in each column of this dataset is IID (Independent and Identically Distributed) therefore, for any random column of this dataset, X where X can be 'radius_mean' or 'testure_mean' or anything else, the Log Likelihood function is evaluated as: \n",
        "\n",
        "\\begin{equation}\n",
        "\\log_e L(\\mu,\\sigma) = \\log_e P(X=x_1\\cap X=x_2\\cap .........X=x_N)\n",
        "\\end{equation}\n",
        "For Normal Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNJ1PFkDtk7f"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log_e L(\\mu, \\sigma) = \\log_e\\prod\\limits_{i=0}^{N}\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}e^\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMgMcgawtk7f"
      },
      "source": [
        "\\begin{equation}\n",
        "\\log_e L(\\mu, \\sigma) = \\sum\\limits_{i=0}^{N}\\log_e\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}e^\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\n",
        "\\end{equation}\n",
        "Here, the population mean and population standard deviation estimator best estimate for normal distribution can be evaluated by taking the derivative of the above function with respect to $\\mu$ and $\\sigma$ and when we do that, that is:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\log_e L(\\mu, \\sigma)}{\\partial\\mu} = 0\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4GSdb35tk7f"
      },
      "source": [
        "\\begin{equation}\n",
        "\\frac{\\partial log_e L(\\mu, \\sigma)}{\\partial\\sigma} = 0\n",
        "\\end{equation}\n",
        "\n",
        "We get,\n",
        "\\begin{equation}\n",
        "\\mu_\\text{best,normal} = \\frac{\\sum\\limits_{i=0}^{N}{X_i}}{N}\n",
        "\\end{equation}\n",
        "\n",
        "And, \n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_\\text{best,normal} = \\sqrt{\\frac{\\sum\\limits_{i=0}^{N}{(x_i-\\mu_\\text{best,normal})^2}}{N}}\n",
        "\\end{equation}\n",
        "\n",
        "Which is sample mean and sample standard deviation, therefore these are the best estimates of the population parameters of Normal Distribution for the best fit on our column data. \n",
        "\n",
        "Similarly, we can find the values of the best estimators of the population parameter of Rayliegh Distribution by following the above mentioned steps, and we get the following value for the best estimate in case of Rayleigh Distribution:\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_\\text{best,rayleigh} = \\sqrt{\\frac{\\sum\\limits_{i=0}^{N}{x_i^2}}{2N}}\n",
        "\\end{equation}\n",
        "\n",
        "So, these best estimates of the MVU Estimators of respective population parameters of respective Probability Distributions will maximize the Log Likelihood Function values for respective probability distributions and hence will result in best fit of respective distributions. Now, to determine the bestest fit among both of the distributions, we have to select that distribution for which the Log Likelihood Function is the highest among both already maximized values. \n",
        "\n",
        "Now, in our case N = 569, so the best estimates of the MVU estimators of the population parameters of respective probability distributions are given by:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mu_\\text{best,normal} = \\frac{\\sum\\limits_{i=0}^{569}{x_i}}{569}\n",
        "\\end{equation}\n",
        "\n",
        "And, \n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_\\text{best,normal} = \\sqrt{\\frac{\\sum\\limits_{i=0}^{569}{(x_i-\\mu_\\text{best,normal})^2}}{569}}\n",
        "\\end{equation}\n",
        "\n",
        "For Normal Distribution\n",
        "\n",
        "And, \n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma_\\text{best,rayleigh} = \\sqrt{\\frac{\\sum\\limits_{i=0}^{569}{x_i^2}}{2*569}}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Therefore, the maximized values of Log Likelihood Function for the case of both the probability distributions is given by:\n",
        "\n",
        "\\begin{equation}\n",
        "L_\\text{max,normal} = \\log_e L(\\mu_\\text{best,normal},\\sigma_\\text{best,normal})\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkYDxIUstk7g"
      },
      "source": [
        "\\begin{equation}\n",
        "L_\\text{max,normal} = \\sum\\limits_{i=0}^{569}\\log_e\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma_\\text{best,normal}}e^\\frac{(x_i-\\mu_\\text{best,normal})^2}{2\\sigma_\\text{best,normal}^2}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "For Normal Distribution\n",
        "\n",
        "And,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neho67KLtk7g"
      },
      "source": [
        "Similarly, maximized value of Log Likelihood Function for Rayleigh Distribution can be calculated as we have just calculated for Normal Distribution. \n",
        "\\begin{equation}\n",
        "L_\\text{max,rayleigh} = \\log_e L(\\sigma_\\text{best,rayleigh})\n",
        "\\end{equation}\n",
        "\n",
        "Now, the column data will be considered to be sampled from Normal Distribution if:\n",
        "\n",
        "\\begin{equation}\n",
        "L_\\text{max,normal} > L_\\text{max,rayleigh}\n",
        "\\end{equation}\n",
        "\n",
        "else:\n",
        "\n",
        "column data will be considered to be sampled from Rayleigh Distribution.\n",
        "\n",
        "Therefore, in order to do all that, we are going to create following set of functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhUy785itk7g"
      },
      "source": [
        "def calculate_L_max_normal(column_name):\n",
        "    \n",
        "    mu_best_normal = data[column_name].mean()\n",
        "    \n",
        "    sigma_best_normal = data[column_name].std()\n",
        "    \n",
        "    L_max_normal = sum(st.norm.logpdf(data[column_name],mu_best_normal,sigma_best_normal))\n",
        "    \n",
        "    return L_max_normal"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3DdT1KCtk7i"
      },
      "source": [
        "def calculate_L_max_rayleigh(column_name):\n",
        "    \n",
        "    sigma_best_rayleigh = np.sqrt(data[column_name]**2/2*(len(data[column_name])))\n",
        "    \n",
        "    L_max_rayleigh = sum(st.rayleigh.logpdf(data[column_name],sigma_best_rayleigh))\n",
        "\n",
        "    return L_max_rayleigh"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22k09C0Ttk7k"
      },
      "source": [
        "def determine_distribution_type(column_name):\n",
        "    \n",
        "    column_type=determine_random_variable_type(column_name)\n",
        "    \n",
        "    if column_type == 'discrete':\n",
        "        \n",
        "       distrinution = \"bionomial\" if (data[column_name].nunique())==2 else \"Multinomial\" \n",
        "       return distrinution \n",
        "    else:\n",
        "        # negative log likelihood\n",
        "        L_max_normal  = -(calculate_L_max_normal(column_name))\n",
        "        \n",
        "        L_max_rayleigh  = -(calculate_L_max_rayleigh(column_name))\n",
        "        \n",
        "        if L_max_normal > L_max_rayleigh:\n",
        "            \n",
        "            return 'normal'\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            return 'rayleigh'"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q8RPJz5cKWN",
        "outputId": "40ff843e-7775-44ed-c2a4-7200ab62a2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "determine_distribution_type('diagnosis')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bionomial'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Z4EmLkhapR"
      },
      "source": [
        "# To print details of all columns "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQV8zn3aNxC",
        "outputId": "e2d80b98-53e8-415d-ef9b-08a2b55f1aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for columns in data.columns:\n",
        "    print(columns,'\\t','=',[determine_random_variable_type(columns)],[determine_distribution_type(columns)],'\\n')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diagnosis \t = ['discrete'] ['bionomial'] \n",
            "\n",
            "radius_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "texture_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "perimeter_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "area_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "smoothness_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "compactness_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concavity_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concave points_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "symmetry_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "fractal_dimension_mean \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "radius_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "texture_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "perimeter_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "area_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "smoothness_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "compactness_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concavity_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concave points_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "symmetry_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "fractal_dimension_se \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "radius_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "texture_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "perimeter_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "area_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "smoothness_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "compactness_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concavity_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "concave points_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "symmetry_worst \t = ['continous'] ['rayleigh'] \n",
            "\n",
            "fractal_dimension_worst \t = ['continous'] ['rayleigh'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpX1JxtKi4wm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}